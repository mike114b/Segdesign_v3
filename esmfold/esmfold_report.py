import os
import re
import pandas as pd
import biotite.structure.io as bsio
import shutil
from Bio import SeqIO
from Bio.SeqRecord import SeqRecord
from Bio.Seq import Seq
import sys
import argparse
root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
# å°†æ ¹ç›®å½•æ·»åŠ åˆ° Python çš„æ¨¡å—æœç´¢è·¯å¾„ä¸­
sys.path.append(root_dir)
from dssp.dssp import run_dssp
from dssp.dsspcsv import dssp_to_csv
from hmmer.pdb_to_fasta import pdb_to_fasta


def parse_args():
    parser = argparse.ArgumentParser(description='Protein 3D Structure Prediction(esmfold)', formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('--fasta_folder', type=str, help="Folder for storing sequence files")
    parser.add_argument('--esmfold_folder', type=str, help="The folder where esmfold's output data is stored")
    parser.add_argument('--original_protein_chain_path', type=str,
                        help="The path to the initial protein chain's PDB file. If the hmmer module has been used, the path is:{hmmer_out_folder}/target_chain_pdb/{your_pdb}")
    parser.add_argument('--plddt_threshold', type=float, help='pLDDT selection threshold')
    parser.add_argument('--seq_range_str', type=str, help='Enter the area to be modified, in the format: start position-end position, such as 1-10')
    return parser.parse_args()


def seqs_dict(fasta_folder):
    """è¯»å–fastaçš„æ–‡ä»¶å¤¹ï¼Œç”Ÿæˆåç§°â€”â€”åºåˆ—å­—å…¸"""
    seq_dict = {}
    filenames = sorted(os.listdir(fasta_folder), key=natural_sort_key)
    for filename in filenames:
        file_path = os.path.join(fasta_folder, filename)
        file_name = os.path.splitext(filename)[0]
        ndx = 0
        sub_to_orig = {}
        for record in SeqIO.parse(file_path, "fasta"):
            # åˆ›å»ºå­åºåˆ—ID
            sub_id = f'{file_name}_{ndx}'
            sub_to_orig[sub_id] = str(record.seq)
            ndx += 1
        seq_dict[file_name] = sub_to_orig
    return seq_dict
        
def pdb_dict(pdb_folder):
    pdb_path_dict = {}
    foldernames = sorted(os.listdir(pdb_folder), key=natural_sort_key)
    for foldername in foldernames:
        folder = os.path.join(pdb_folder, foldername)
        filenames = sorted(os.listdir(folder), key=natural_sort_key)
        file_path_dict = {}
        for filename in filenames:
            file_path = os.path.join(folder, filename)
            file_name = os.path.splitext(filename)[0]
            file_path_dict[file_name] = file_path
        pdb_path_dict[foldername] = file_path_dict

    return pdb_path_dict


def filter_plddt(fasta_folder, pdb_folder, output_folder, plddt_threshold):
    filter_files_folder = os.path.join(output_folder, 'filter_files')
    if not os.path.exists(filter_files_folder):
        os.makedirs(filter_files_folder,  exist_ok=True)
    seqs = seqs_dict(fasta_folder)
    pdb_paths = pdb_dict(pdb_folder)
    with open(f'{output_folder}/filter_result.fa', "w") as fl:
        for key, value in seqs.items():
            filter_files_folder2 = os.path.join(filter_files_folder, key)
            if not os.path.exists(filter_files_folder2):
                os.makedirs(filter_files_folder2, exist_ok=True)
            with open(f'{filter_files_folder2}/{key}_filter.fa', "a+") as f:
                f.truncate(0)
                for sub_key, seq in value.items():
                    pdb_path = pdb_paths[key][sub_key]
                    struct = bsio.load_structure(pdb_path, extra_fields=["b_factor"])
                    plddt = struct.b_factor.mean()
                    if plddt > plddt_threshold:
                        filter_pdb_path = os.path.join(filter_files_folder2, f'{sub_key}.pdb')
                        shutil.copy(pdb_path, filter_pdb_path)
                        f.write(f'>{sub_key}, pLDDT={plddt}\n')
                        f.write(f'{seq}\n')
                        fl.write(f'>{sub_key}, pLDDT={plddt}\n')
                        fl.write(f'{seq}\n')
    print('pLDDT filter done!\n')
    return





    ndx = []
    plddt_l = []
    i = 0
    while True:
        file_name = f'{folder_name}_{i}.pdb'
        file_path = os.path.join(input_folder, file_name)
        if os.path.exists(file_path):
            struct = bsio.load_structure(file_path, extra_fields=["b_factor"])
            plddt = struct.b_factor.mean()
            if plddt > plddt_threshold:
                ndx.append(i)
                plddt_l.append(plddt)
                out_path = os.path.join(output_folder, file_name)
                shutil.copy(file_path, out_path)
        else:
            break
        i += 1
    return ndx, plddt_l







def natural_sort_key(filename):
    """ç”Ÿæˆè‡ªç„¶æ’åºçš„keyï¼šå°†æ–‡ä»¶åæ‹†åˆ†ä¸ºå­—ç¬¦ä¸²å’Œæ•°å­—éƒ¨åˆ†ï¼Œæ•°å­—è½¬æ•´æ•°"""
    parts = re.split(r'(\d+)', os.path.splitext(filename)[0])
    key = []
    for part in parts:
        if part.isdigit():
            key.append(int(part))
        else:
            key.append(part)
    return key


def extract_global_score(desc):
    """ä»FASTAæè¿°ä¿¡æ¯ä¸­æå–global_scoreæ•°å€¼"""
    pattern = re.compile(r'global_score[:=/-]\s*(\d+\.?\d*)', re.IGNORECASE)
    match = pattern.search(desc)
    if match:
        score_str = match.group(1)
        return float(score_str) if '.' in score_str else int(score_str)
    return None


def parse_seq_range(seq_range_str):
    """è§£æåºåˆ—åŒºé—´å­—ç¬¦ä¸²ï¼ˆå¦‚"1-4"ï¼‰ï¼Œè½¬æ¢ä¸ºPythonåˆ‡ç‰‡çš„start/endç´¢å¼•ï¼ˆ0-basedï¼‰"""
    if not re.match(r'^\d+-\d+$', seq_range_str):
        raise ValueError(f"åŒºé—´æ ¼å¼é”™è¯¯ï¼è¯·è¾“å…¥å¦‚'1-4'/'2-2'çš„æ ¼å¼ï¼Œå½“å‰è¾“å…¥ï¼š{seq_range_str}")

    start_1based, end_1based = map(int, seq_range_str.split('-'))
    if start_1based < 1 or end_1based < 1:
        raise ValueError(f"åŒºé—´æ•°å­—å¿…é¡»ä¸ºæ­£æ•´æ•°ï¼å½“å‰è¾“å…¥ï¼š{seq_range_str}")
    if start_1based > end_1based:
        raise ValueError(f"èµ·å§‹æ•°å­—ä¸èƒ½å¤§äºç»“æŸæ•°å­—ï¼å½“å‰è¾“å…¥ï¼š{seq_range_str}")

    start_idx = start_1based - 1
    end_idx = end_1based
    return start_idx, end_idx


def parse_uploaded_file(uploaded_file_path):
    """
    è§£æä¸Šä¼ çš„æ–‡ä»¶ï¼Œæå–ç›®æ ‡åç§°åˆ—è¡¨å’ŒpLDDTæ•°å€¼
    å‚æ•°: uploaded_file_path (str): ä¸Šä¼ æ–‡ä»¶çš„è·¯å¾„ï¼ˆå¦‚filter_result.fa.txtï¼‰
    è¿”å›: tuple: (target_namesåˆ—è¡¨, plddt_dict)
    """
    target_names = []
    plddt_dict = {}
    # åŒ¹é… ">åç§°, pLDDT=æ•°å€¼" æ ¼å¼
    pattern = re.compile(r'^>(\S+),\s*pLDDT=(\d+\.?\d*)$')

    with open(uploaded_file_path, 'r') as f:
        for line in f:
            line = line.strip()
            if line.startswith('>'):  # åªå¤„ç†æè¿°è¡Œ
                match = pattern.match(line)
                if match:
                    name = match.group(1)  # æå–åç§°ï¼ˆå¦‚Dusp4_1_0_0ï¼‰
                    plddt_val = float(match.group(2))  # æå–pLDDTæ•°å€¼ï¼ˆè½¬æ¢ä¸ºfloatï¼‰
                    target_names.append(name)
                    plddt_dict[name] = plddt_val
                else:
                    print(f"è­¦å‘Šï¼šä¸Šä¼ æ–‡ä»¶ä¸­è¯¥è¡Œæ ¼å¼ä¸åŒ¹é…ï¼Œè·³è¿‡ï¼š{line}")

    if not target_names:
        print("è­¦å‘Šï¼šä¸Šä¼ æ–‡ä»¶ä¸­æœªæå–åˆ°æœ‰æ•ˆåç§°å’ŒpLDDTæ•°å€¼")
    return target_names, plddt_dict


def process_fasta_with_filter(folder_path, uploaded_file_path, csv_folder_path, seq_range_str):
    """
    å¤„ç†fastaæ–‡ä»¶å¤¹+ä¸Šä¼ æ–‡ä»¶ç­›é€‰ï¼Œç”Ÿæˆäº”ä¸ªå­—å…¸
    å‚æ•°:
        folder_path (str): fastaæ–‡ä»¶å¤¹è·¯å¾„
        uploaded_file_path (str): ä¸Šä¼ æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚filter_result.fa.txtï¼‰
        seq_range_str (str): åºåˆ—åŒºé—´å­—ç¬¦ä¸²ï¼ˆå¦‚"1-4"ï¼‰
    è¿”å›:
        tuple: (ç­›é€‰ååºåˆ—å­—å…¸, ç­›é€‰åä¿¡æ¯å­—å…¸, ç­›é€‰åglobal_scoreå­—å…¸, ç­›é€‰åå­åºåˆ—å­—å…¸, pLDDTå­—å…¸)
    """
    # æ­¥éª¤1ï¼šè§£æä¸Šä¼ æ–‡ä»¶ï¼Œè·å–ç›®æ ‡åç§°å’ŒpLDDTå­—å…¸
    target_names, plddt_dict = parse_uploaded_file(uploaded_file_path)
    if not target_names:
        return {}, {}, {}, {}, {}

    # æ­¥éª¤2ï¼šè§£æåºåˆ—åŒºé—´
    try:
        start_idx, end_idx = parse_seq_range(seq_range_str)
    except ValueError as e:
        print(f"åŒºé—´è§£æå¤±è´¥ï¼š{e}")
        return {}, {}, {}, {}, {}

    # æ­¥éª¤3ï¼šå¤„ç†fastaæ–‡ä»¶å¤¹ï¼Œè·å–å®Œæ•´å­—å…¸ï¼ˆåŒä¹‹å‰é€»è¾‘ï¼‰
    fa_files = [
        f for f in os.listdir(folder_path)
        if f.endswith('.fa') and os.path.isfile(os.path.join(folder_path, f))
    ]
    if not fa_files:
        print("è­¦å‘Šï¼šæ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°.faæ–‡ä»¶")
        return {}, {}, {}, {}, {}
    fa_files.sort(key=natural_sort_key)

    def parse_fasta(file_path):
        """è§£æfastaæ–‡ä»¶ï¼Œè¿”å›(æè¿°ä¿¡æ¯, åºåˆ—)åˆ—è¡¨"""
        sequences = []
        current_desc = None
        current_seq = []
        with open(file_path, 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                if line.startswith('>'):
                    if current_desc is not None:
                        sequences.append((current_desc, ''.join(current_seq)))
                    current_desc = line[1:]
                    current_seq = []
                else:
                    current_seq.append(line)
            if current_desc is not None:
                sequences.append((current_desc, ''.join(current_seq)))
        return sequences

    # ç”Ÿæˆå®Œæ•´çš„å››ä¸ªå­—å…¸
    full_seq_dict = {}
    full_info_dict = {}
    full_global_score_dict = {}
    full_subseq_dict = {}
    s_dict = ss_dict(target_names, csv_folder_path, seq_range_str)
    for file_name in fa_files:
        file_path = os.path.join(folder_path, file_name)
        seq_info_list = parse_fasta(file_path)
        base_name = os.path.splitext(file_name)[0]
        for idx, (desc, seq) in enumerate(seq_info_list):
            new_name = f"{base_name}_{idx}"
            full_seq_dict[new_name] = seq
            full_info_dict[new_name] = desc
            full_global_score_dict[new_name] = extract_global_score(desc)
            full_subseq_dict[new_name] = seq[start_idx:end_idx]

    # æ­¥éª¤4ï¼šæŒ‰ä¸Šä¼ æ–‡ä»¶çš„ç›®æ ‡åç§°ç­›é€‰å››ä¸ªå­—å…¸
    filtered_seq_dict = {name: full_seq_dict[name] for name in target_names if name in full_seq_dict}
    filtered_info_dict = {name: full_info_dict[name] for name in target_names if name in full_info_dict}
    filtered_global_score_dict = {name: full_global_score_dict[name] for name in target_names if
                                  name in full_global_score_dict}
    filtered_subseq_dict = {name: full_subseq_dict[name] for name in target_names if name in full_subseq_dict}

    # æç¤ºæœªåŒ¹é…åˆ°çš„åç§°
    unmatched_names = [name for name in target_names if name not in full_seq_dict]
    if unmatched_names:
        print(f"è­¦å‘Šï¼šä»¥ä¸‹åç§°åœ¨fastaæ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°åŒ¹é…é¡¹ï¼š{unmatched_names}")

    return filtered_seq_dict, filtered_info_dict, filtered_global_score_dict, filtered_subseq_dict, plddt_dict, s_dict


def get_file_dict(folder_path):
    """
    é€’å½’è¯»å–æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰æ–‡ä»¶ï¼Œç”Ÿæˆ{æ— åç¼€æ–‡ä»¶å: ç»å¯¹è·¯å¾„}çš„å­—å…¸
    :param folder_path: ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„
    :return: æ–‡ä»¶å-è·¯å¾„å­—å…¸
    """
    file_dict = {}

    # éªŒè¯è·¯å¾„åˆæ³•æ€§
    if not os.path.exists(folder_path):
        raise FileNotFoundError(f"é”™è¯¯ï¼šè·¯å¾„ {folder_path} ä¸å­˜åœ¨")
    if not os.path.isdir(folder_path):
        raise NotADirectoryError(f"é”™è¯¯ï¼š{folder_path} ä¸æ˜¯æœ‰æ•ˆçš„æ–‡ä»¶å¤¹è·¯å¾„")

    # é€’å½’éå†æ‰€æœ‰æ–‡ä»¶ï¼ˆåŒ…æ‹¬å­æ–‡ä»¶å¤¹ï¼‰
    for root, _, files in os.walk(folder_path):
        for file_name in files:
            # æ‹¼æ¥æ–‡ä»¶ç»å¯¹è·¯å¾„
            file_abs_path = os.path.abspath(os.path.join(root, file_name))
            # æå–æ— åç¼€çš„æ–‡ä»¶åï¼ˆå¤„ç†å¤šåç¼€å¦‚a.tar.gzæ—¶ï¼Œä»…å»æ‰æœ€åä¸€ä¸ªåç¼€ï¼‰
            file_name_no_ext = os.path.splitext(file_name)[0]
            # å­˜å…¥å­—å…¸ï¼ˆé‡å¤æ–‡ä»¶åä¼šè¦†ç›–ï¼‰
            file_dict[file_name_no_ext] = file_abs_path

    return file_dict

def ss_dict(target_names, csv_folder_path, seq_range_str):
    s_dict = {}
    start, end = parse_seq_range(seq_range_str)
    print('start:',start)
    print(end)

    file_path_dict = get_file_dict(csv_folder_path)
    for file_name in target_names:
        if file_name in file_path_dict:
            file_path = file_path_dict[file_name]
            df = pd.read_csv(file_path)
            secondary_structure = df["Secondary_Structure"]
            #print('secondary_structure:',secondary_structure)

            if start < 0 or end > len(secondary_structure):
                print(f"è­¦å‘Šï¼šåç§°'{file_name}'çš„èŒƒå›´è¶…å‡ºäºŒçº§ç»“æ„é•¿åº¦ï¼Œå·²è·³è¿‡")
                continue
            target_struct = ''.join(secondary_structure[start:end].tolist())
            s_dict[file_name] = target_struct
    return s_dict


import csv


def dict_list_to_csv(dict_list, header_list, csv_file_path):
    """
    ç”ŸæˆæŒ‡å®šæ ·å¼çš„CSVæ–‡ä»¶ï¼ˆæ”¯æŒä»»æ„æ•°é‡å±æ€§åˆ—/å­—å…¸ï¼‰ï¼š
    è¡¨å¤´ï¼šåç§°       å±æ€§0åç§°    å±æ€§1åç§°    å±æ€§2åç§°    å±æ€§3åç§° ...
    å†…å®¹ï¼šåç§°0     å±æ€§00       å±æ€§10       å±æ€§20       å±æ€§30
          åç§°1     å±æ€§01       å±æ€§11       å±æ€§21       å±æ€§31
          åç§°2     å±æ€§02       å±æ€§12       å±æ€§22       å±æ€§32

    å‚æ•°ï¼š
    dict_list -- ä»»æ„é•¿åº¦çš„å­—å…¸åˆ—è¡¨ï¼ˆæ¯ä¸ªå­—å…¸å¯¹åº”1åˆ—å±æ€§å€¼ï¼‰
    header_list -- è¡¨å¤´åˆ—è¡¨ï¼ˆç¬¬ä¸€ä¸ªå…ƒç´ ä¸º"åç§°"ï¼Œåç»­Nä¸ªå…ƒç´ å¯¹åº”Nä¸ªå­—å…¸çš„å±æ€§åï¼‰
    csv_file_path -- è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„
    """
    # è¾“å…¥åˆæ³•æ€§æ£€æŸ¥ï¼ˆé€šç”¨é€‚é…ï¼Œä¸ç®¡å¤šå°‘å­—å…¸éƒ½ç”Ÿæ•ˆï¼‰
    if not dict_list:
        raise ValueError("å­—å…¸åˆ—è¡¨ä¸èƒ½ä¸ºç©ºï¼")
    if len(header_list) != len(dict_list) + 1:
        raise ValueError(
            f"è¡¨å¤´åˆ—è¡¨é•¿åº¦åº”ä¸º{len(dict_list) + 1}ï¼ˆ1ä¸ªåç§°åˆ— + {len(dict_list)}ä¸ªå±æ€§åˆ—ï¼‰ï¼\n"
            f"å½“å‰è¡¨å¤´é•¿åº¦ï¼š{len(header_list)}ï¼Œå­—å…¸æ•°é‡ï¼š{len(dict_list)}"
        )
    # æ ¡éªŒæ‰€æœ‰å­—å…¸çš„keyæ˜¯å¦ä¸€è‡´ï¼ˆé¿å…æ•°æ®é”™ä½ï¼‰
    first_keys = set(dict_list[0].keys())
    for i, d in enumerate(dict_list[1:], 1):
        if set(d.keys()) != first_keys:
            raise ValueError(f"ç¬¬{i + 1}ä¸ªå­—å…¸çš„keyä¸ç¬¬ä¸€ä¸ªå­—å…¸ä¸ä¸€è‡´ï¼")

    # æå–è¡Œåï¼ˆåç§°0ã€åç§°1...ï¼‰å¹¶æŒ‰æ•°å­—æ’åº
    def sort_key(name):
        num = ''.join([c for c in name if c.isdigit()])
        return int(num) if num else 0

    row_names = dict_list[0].keys()#sorted(dict_list[0].keys(), key=sort_key)

    # æ„å»ºæ¯è¡Œæ•°æ®ï¼ˆè‡ªåŠ¨é€‚é…æ‰€æœ‰å­—å…¸ï¼‰
    csv_data = []
    for name in row_names:
        # ä¸€è¡Œæ•°æ® = [è¡Œå] + è¯¥åç§°åœ¨æ¯ä¸€ä¸ªå­—å…¸ä¸­çš„å€¼ï¼ˆè‡ªåŠ¨éå†æ‰€æœ‰å­—å…¸ï¼‰
        row = [name] + [d[name] for d in dict_list]
        csv_data.append(row)

    # å†™å…¥CSVï¼ˆé€šç”¨é€»è¾‘ï¼Œæ— éœ€ä¿®æ”¹ï¼‰
    with open(csv_file_path, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        writer.writerow(header_list)  # å†™å…¥è¡¨å¤´
        writer.writerows(csv_data)  # å†™å…¥æ‰€æœ‰è¡Œ

    print(f"âœ… CSVæ–‡ä»¶å·²ç”Ÿæˆï¼š{csv_file_path}")
    #print(f"ğŸ“Š æ•°æ®ç»´åº¦ï¼š{len(row_names)}è¡Œï¼ˆåç§°0/1/2...ï¼‰ Ã— {len(dict_list)}åˆ—ï¼ˆå±æ€§åˆ—ï¼‰")

def pdb_to_dssp_csv(pdb_folder, dssp_folder,csv_folder):
    foldernames = os.listdir(pdb_folder)
    for foldername in foldernames:
        folder_path = os.path.join(pdb_folder, foldername)
        dssp_output_folder = os.path.join(dssp_folder, foldername)
        csv_file_path = os.path.join(csv_folder, foldername)
        if not os.path.exists(dssp_output_folder):
            os.makedirs(dssp_output_folder, exist_ok=True)
        if not os.path.exists(csv_file_path):
            os.makedirs(csv_file_path, exist_ok=True)
        for file in os.listdir(folder_path):
            # æ‹¼æ¥å®Œæ•´è·¯å¾„
            file_path = os.path.join(folder_path, file)
            # åˆ¤æ–­æ˜¯å¦æ˜¯æ–‡ä»¶ï¼ˆæ’é™¤æ–‡ä»¶å¤¹ï¼‰
            if os.path.isfile(file_path):
                file_name = os.path.splitext(file)[0]
                dssp_out_file_path = os.path.join(dssp_output_folder, f'{file_name}.dssp')
                csv_out_file_path = os.path.join(csv_file_path, f'{file_name}.csv')
                # åˆ¤æ–­æ–‡ä»¶åç¼€æ˜¯å¦åœ¨ç›®æ ‡åˆ—è¡¨ä¸­ï¼ˆåŒºåˆ†å¤§å°å†™ï¼‰

                if file_path.endswith('.pdb'):
                    run_dssp(
                        input_path=file_path,
                        output_path=dssp_out_file_path
                    )
                    dssp_to_csv(
                        input_file=dssp_out_file_path,
                        output_file=csv_out_file_path
                    )

    return

def original_protein_chain(original_protein_chain_path,output_folder, seq_range_str):
    filename = os.path.basename(original_protein_chain_path)
    protein_name = os.path.splitext(filename)[0]
    out_original_protein_files = os.path.join(output_folder, 'original_protein_files')
    if not os.path.exists(out_original_protein_files):
        os.makedirs(out_original_protein_files, exist_ok=True)
    fasta_path = os.path.join(out_original_protein_files, f'{protein_name}.fasta')
    pdb_to_fasta(original_protein_chain_path, fasta_path)
    dssp_path = os.path.join(out_original_protein_files, f'{protein_name}.dssp')
    run_dssp(original_protein_chain_path, dssp_path)
    csv_path = os.path.join(out_original_protein_files, f'{protein_name}.csv')
    dssp_to_csv(dssp_path, csv_path)

    seq_record = SeqIO.read(fasta_path, "fasta")
    start, end = parse_seq_range(seq_range_str)
    dict_seq = {protein_name: seq_record.seq}
    dict_seq_range = {protein_name: seq_record.seq[start:end]}
    dict_gs = {protein_name: '-'}
    dict_plddt = {protein_name: '-'}

    df = pd.read_csv(csv_path)
    secondary_structure = df["Secondary_Structure"]
    #print('secondary_structure:', secondary_structure)
    target_struct = ''.join(secondary_structure[start:end].tolist())
    dict_s = {protein_name: target_struct}
    return  dict_seq, dict_seq_range, dict_gs, dict_plddt, dict_s

def ss8_to_ss3(ss8_dict):
    char_map = {
        'H': 'H',
        'E': 'E',
        'B': 'E',
        'G': 'H',
        'I': 'H',
        'T': 'C',
        'S': 'C',
        'C': 'C',
    }
    processed_dict = {
        key: ''.join([str(char_map.get(char, char)) for char in str(value)])
        for key, value in ss8_dict.items()
    }
    return processed_dict


def data_organization(
        fasta_folder,
        pdb_folder,
        filter_result_path,
        dssp_folder,
        csv_folder_path,
        seq_range_str,
        original_protein_chain_path = None,
        output_folder = None
):
    pdb_to_dssp_csv(pdb_folder=pdb_folder, dssp_folder=dssp_folder, csv_folder=csv_folder_path)
    res = process_fasta_with_filter(fasta_folder, filter_result_path, csv_folder_path, seq_range_str)
    filtered_seq, filtered_info, filtered_gs, filtered_subseq, plddt_dict, s_dict = res
    if original_protein_chain_path is not None:
        dict_seq, dict_seq_range, dict_gs, dict_plddt, dict_s = original_protein_chain(
            original_protein_chain_path = original_protein_chain_path,
            output_folder = output_folder,
            seq_range_str = seq_range_str,
        )
        filtered_seq = {**dict_seq, **filtered_seq}
        #print(filtered_seq)
        filtered_subseq = {**dict_seq_range, **filtered_subseq}
        #print(filtered_subseq)
        filtered_gs = {**dict_gs, **filtered_gs}
        #print(filtered_gs)
        s_dict = {**dict_s, **s_dict}
        #print(s_dict)
        plddt_dict = {**dict_plddt, **plddt_dict}
        #print(plddt_dict)
    range_dict = {key: seq_range_str for key in filtered_seq}
    s3_dict = ss8_to_ss3(s_dict)
    dict_list = [filtered_seq, range_dict, filtered_subseq, s_dict, s3_dict, filtered_gs, plddt_dict]
    header_list = ['name', 'sequence', 'design_area', f'sequence_design',
                   f'ss_8', 'ss_3', 'global_score', 'pLDDT']
    dict_list_to_csv(
        dict_list=dict_list,
        header_list=header_list,
        csv_file_path=f'{output_folder}/filter_result.csv')
    return

def main():
    # é…ç½®å‚æ•°ï¼ˆæ›¿æ¢ä¸ºå®é™…è·¯å¾„ï¼‰
    fasta_folder = "fasta"  # fastaæ–‡ä»¶å¤¹è·¯å¾„
    uploaded_file_path = "out/filter_result.fa"  # ä¸Šä¼ æ–‡ä»¶è·¯å¾„
    csv_folder_path = "out/filter_csv"
    seq_range_str = "1-4"  # åºåˆ—åŒºé—´ï¼ˆå¦‚"1-4"ã€"2-2"ï¼‰

    # è°ƒç”¨å‡½æ•°
    res = process_fasta_with_filter(fasta_folder, uploaded_file_path, csv_folder_path, seq_range_str)
    filtered_seq, filtered_info, filtered_gs, filtered_subseq, plddt_dict, s_dict = res
    print(s_dict)
    # æ‰“å°éªŒè¯ç»“æœ
    print("=== ä¸Šä¼ æ–‡ä»¶ä¸­æå–çš„ç›®æ ‡åç§° ===")
    print(list(plddt_dict.keys()))

    print(f"\n=== ç­›é€‰å-åŸå§‹åºåˆ—å­—å…¸ï¼ˆ{len(filtered_seq)}æ¡ï¼‰===")
    for name, seq in filtered_seq.items():
        print(f"{name}: {seq[:50]}...")

    print(f"\n=== ç­›é€‰å-æŒ‡å®šåŒºé—´({seq_range_str})å­åºåˆ—å­—å…¸ ===")
    for name, sub_seq in filtered_subseq.items():
        print(f"{name}: {sub_seq}")

    print("\n=== ç­›é€‰å-ä¿¡æ¯å­—å…¸ ===")
    for name, info in filtered_info.items():
        print(f"{name}: {info}")

    print("\n=== ç­›é€‰å-global_scoreå­—å…¸ ===")
    for name, score in filtered_gs.items():
        print(f"{name}: {score}")

    print("\n=== ç¬¬äº”ä¸ª-pLDDTå­—å…¸ ===")
    for name, plddt in plddt_dict.items():
        print(f"{name}: {plddt}")

    print("\n=== ç¬¬å…­ä¸ª-sså­—å…¸ ===")
    for name, ss in s_dict.items():
        print(f"{name}: {ss}")
    # pdb_to_dssp_csv(pdb_folder='out/filter_files', dssp_folder='out/filter_dssp',csv_folder='out/filter_csv')
    dict_list = [filtered_seq, filtered_subseq, filtered_gs, s_dict, plddt_dict]
    header_list = ['name', 'seq', f'seq({seq_range_str})', 'global_score', f'secondary_structure({seq_range_str})',
                   'pLDDT']
    dict_list_to_csv(
        dict_list=dict_list,
        header_list=header_list,
        csv_file_path='out/filter_result.csv')

    data_organization(
        fasta_folder='fasta',
        pdb_folder='out/structure_prediction_files',
        filter_result_path=f'out/filter_result.fa',
        dssp_folder='out/filter_dssp',
        csv_folder_path=f'out/filter_csv',
        seq_range_str='1-6',
        original_protein_chain_path='/home/xieweilong/Segdesign_v2/work/hmmer_out/target_chain_pdb/Dusp4_A.pdb',
        output_folder='out'
    )
    # pdb_to_dssp_csv(pdb_folder='out/filter_files', dssp_folder='out/filter_dssp',csv_folder='out/filter_csv')
    # print(get_file_dict(folder_path='out/filter_csv'))


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    args = parse_args()
    esmfold_folder = os.path.expanduser(args.esmfold_folder)
    fasta_folder = os.path.expanduser(args.fasta_folder)
    pdb_folder = os.path.join(esmfold_folder, 'structure_prediction_files')
    filter_result_path = os.path.join(esmfold_folder, 'filter_result.fa')
    dssp_folder = os.path.join(esmfold_folder, 'filter_dssp')
    csv_folder = os.path.join(esmfold_folder, 'filter_csv')
    seq_range_str = args.seq_range_str
    original_protein_chain_path = os.path.expanduser(args.original_protein_chain_path)
    out_folder = esmfold_folder
    plddt_threshold = args.plddt_threshold

    filter_plddt(
        fasta_folder=fasta_folder,
        pdb_folder=pdb_folder,
        output_folder=out_folder,
        plddt_threshold=plddt_threshold
    )


    data_organization(
        fasta_folder=fasta_folder,
        pdb_folder=pdb_folder,
        filter_result_path=filter_result_path,
        dssp_folder=dssp_folder,
        csv_folder_path=csv_folder,
        seq_range_str=seq_range_str,
        original_protein_chain_path=original_protein_chain_path,
        output_folder= out_folder
    )